{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import resnet as rnet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f\"using device {device}\")\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "filenameSuffix = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateFunc(model, val_loader, batches):\n",
    "    with torch.no_grad():\n",
    "        valacc = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            if i >= batches:\n",
    "                break\n",
    "            if cuda_available: \n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            t = time.time()\n",
    "            prediction = model.forward(images)\n",
    "\n",
    "            valacc = valacc + [get_xent_acc(prediction, targets)]\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        return valacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneh(labels):\n",
    "    oneh_labels = np.zeros([labels.shape[0], 10])\n",
    "    indexes = np.array([np.arange(0,labels.shape[0]), labels.numpy()])\n",
    "    oneh_labels[tuple(indexes)] = 1.0\n",
    "    return torch.tensor(oneh_labels).long()\n",
    "def get_xent_acc(prediction, labels):\n",
    "    prediction = prediction.cpu().data.numpy()\n",
    "    labels = labels.cpu().data.numpy()\n",
    "    predicted_labels = np.argmax(prediction,1)\n",
    "    return sum((predicted_labels - labels) == 0)/predicted_labels.shape[0]\n",
    "def xent_softmax(prediction):\n",
    "    pred = np.exp(prediction.cpu().data.numpy())\n",
    "    divide = np.repeat(pred.sum(1).reshape(pred.shape[0],1), pred.shape[1],1)\n",
    "    pred = np.divide(pred,divide)\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainFunc(model, lossfn, optimizer, data_loader, val_loader, min_lr, max_lr, n_epochs=1, validation_interval=10):\n",
    "    start    = time.time()\n",
    "    accuracy = [] \n",
    "    loss     = []\n",
    "    valacc   = []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    lastEpochs = math.floor(n_epochs/10)\n",
    "    iterations = (n_epochs - lastEpochs) * len(data_loader)\n",
    "    if iterations % 2 != 0:\n",
    "        iterations -= len(data_loader)\n",
    "        lastEpochs += 1\n",
    "        \n",
    "    iterations /= 2\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, min_lr, max_lr, \n",
    "                                                  step_size_up=iterations, step_size_down=iterations, \n",
    "                                                  base_momentum=0.95,\n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "    \n",
    "    print(\"starting training\")\n",
    "    \n",
    "    updateStep = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        data_iterator = iter(data_loader)\n",
    "        \n",
    "        # attempt at annealing\n",
    "        if epoch == n_epochs - lastEpochs:\n",
    "            iterations = lastEpochs * len(data_loader)\n",
    "            scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, min_lr*0.1, min_lr, \n",
    "                                                  step_size_up=0, step_size_down=iterations, \n",
    "                                                  base_momentum=0.95,\n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "        \n",
    "        for i, (images, labels) in enumerate(data_iterator):\n",
    "            t = time.time()\n",
    "\n",
    "            f\"\"\"if we use GPU, input- and target-tensors must be loaded on GPU as well.\"\"\"\n",
    "            if cuda_available: \n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            prediction = model.forward(images)\n",
    "            output     = lossfn(prediction, labels)\n",
    "\n",
    "            accuracy = accuracy + [get_xent_acc(prediction, labels)]\n",
    "            loss     = loss + [output]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output.backward() # calculates gradients \n",
    "            optimizer.step()  # updates weights\n",
    "            scheduler.step()\n",
    "\n",
    "            if validation_interval > 0 and updateStep % validation_interval == 0:\n",
    "                valacc = valacc + validateFunc(model, val_loader, 1)\n",
    "            updateStep += 1\n",
    "\n",
    "        print(f\"\"\"time passed after training {epoch} epochs is {time.time()-start} seconds\"\"\")\n",
    "    return (accuracy, loss, valacc)\n",
    "\n",
    "def cuda(thing):\n",
    "    if cuda_available:\n",
    "        return thing.cuda()\n",
    "    return thing\n",
    "\n",
    "def range_test(net,opt,dataloader,lossfn,min_lr,max_lr,iterations,batchsize):\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(opt, min_lr, max_lr, \n",
    "                                                  step_size_up=iterations, step_size_down=0, \n",
    "                                                  base_momentum=0,\n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "    start    = time.time()\n",
    "    time_int = 100\n",
    "    \n",
    "    accuracy  = []\n",
    "    loss      = []\n",
    "    interval  = 5\n",
    "    i         = 0\n",
    "    while i < iterations:\n",
    "        datait = iter(dataloader)\n",
    "        for n, (images, labels) in enumerate(datait):\n",
    "            images, labels = cuda(images), cuda(labels)\n",
    "            prediction = net.forward(images)\n",
    "            output     = lossfn(prediction, labels)\n",
    "            # Use accuracy on training-set\n",
    "            if i % interval == 0:\n",
    "                accuracy   = accuracy + [get_xent_acc(prediction, labels)]\n",
    "                loss       = loss + [output]\n",
    "            opt.zero_grad()   # clear gradients from previous time-step \n",
    "            output.backward() # calculates gradients \n",
    "            opt.step()        # updates weights\n",
    "            scheduler.step()  # change learning-rate in range_optimizer\n",
    "            if i % time_int == 0:\n",
    "                print(f\"time after {i} iterations: {time.time() - start} seconds\")\n",
    "                \n",
    "            i += 1\n",
    "            if i >= iterations:\n",
    "                break\n",
    "                \n",
    "    print(f\"time after {i} iterations: {time.time() - start} seconds\")\n",
    "            \n",
    "    f\"\"\"make and save plot of accuracy\"\"\"\n",
    "    x1, x2 = [np.linspace(min_lr, max_lr, num) for num in [len(accuracy), len(loss)]]\n",
    "    plt.plot(x1, np.array(accuracy))\n",
    "    momentum = opt.param_groups[-1]['momentum']\n",
    "    weightdecay = opt.param_groups[-1]['weight_decay']\n",
    "    save_file = path+f\"/rangetest{filenameSuffix}/acc_bs{batchsize}_minlr{min_lr}_maxlr{max_lr}_iterations{iterations}_momentum{momentum}_weightdecy{weightdecay}.png\"\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create loss function \n",
    "#### https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_xent = nn.CrossEntropyLoss()\n",
    "loss_mse  = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play with forward and backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNet(batch_size, min_lr=None, max_lr=None):\n",
    "    # Configure\n",
    "    resnet = rnet.resnet56()\n",
    "    optimizer = optim.SGD(resnet.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0.95,\n",
    "                          weight_decay=1e-4)\n",
    "    rt_optimizer = optim.SGD(resnet.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0,\n",
    "                          weight_decay=0)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(path, train=True, transform=transforms.Compose([\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                #transforms.RandomCrop(32, 4),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]), download=True),\n",
    "            batch_size=batch_size, shuffle=True,\n",
    "            num_workers=0, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(path, train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=True)\n",
    "    \n",
    "    cuda(resnet)\n",
    "    \n",
    "    return (resnet, optimizer, rt_optimizer, data_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [(128, 36, 0.04, 0.4),\n",
    "         (256, 47, 0.06, 0.6),\n",
    "         (512, 50, 0.08, 0.8),\n",
    "         (1024, 52, 0.1, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "LambdaLayer\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "LambdaLayer\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Linear\n",
      "ResNet\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0.04 0.4 36 6256.0 4 391\n",
      "starting training\n",
      "time passed after training 0 epochs is 80.87034392356873 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62d028a9536b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrt_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalacc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tr{filenameSuffix}_acc{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tr{filenameSuffix}_loss{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f9cac9011daf>\u001b[0m in \u001b[0;36mtrainFunc\u001b[0;34m(model, lossfn, optimizer, data_loader, val_loader, min_lr, max_lr, n_epochs, validation_interval)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                   mode='triangular', cycle_momentum=False)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (batch_size, epochs, min_lr, max_lr) in enumerate(params):\n",
    "    (model, optimizer, rt_optimizer, data_loader, val_loader) = getNet(batch_size, min_lr, max_lr)\n",
    "    (acc, loss) = range_test(model, rt_optimizer, data_loader, loss_xent, 0, 2, 10000/2**i, batch_size)\n",
    "    np.save(f\"rt{filenameSuffix}_acc{i}\", acc)\n",
    "    np.save(f\"rt{filenameSuffix}_loss{i}\", loss)\n",
    "    torch.save(model.state_dict(), f\"rt{filenameSuffix}_model{i}\")\n",
    "    \n",
    "\n",
    "for i, (batch_size, epochs, min_lr, max_lr) in enumerate(params):\n",
    "    (model, optimizer, rt_optimizer, data_loader, val_loader) = getNet(batch_size, min_lr, max_lr)\n",
    "    (acc, loss, valacc) = trainFunc(model, nn.CrossEntropyLoss(), optimizer, data_loader, val_loader, min_lr, max_lr, epochs, validation_interval=50)\n",
    "    np.save(f\"tr{filenameSuffix}_acc{i}\", acc)\n",
    "    np.save(f\"tr{filenameSuffix}_loss{i}\", loss)\n",
    "    np.save(f\"tr{filenameSuffix}_valacc{i}\", valacc)\n",
    "    torch.save(model.state_dict(), f\"tr{filenameSuffix}_model{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(accuracy, loss, validationacc) = trainFunc(resnet, nn.CrossEntropyLoss(), optimizer, n_epochs=40, validation_interval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.append((accuracy, loss, validationacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0,len(accuracy))\n",
    "plt.plot(x,np.array(accuracy),np.array(loss))\n",
    "x = np.arange(0,len(validationacc))\n",
    "plt.plot(x, np.array(validationacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "valacc = validateFunc(resnet, 100)\n",
    "print(f\"{time.time()-t:2.4f}\\nacc {np.mean(valacc):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda_available:\n",
    "    images = images.cpu()\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet161()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (batch_size, epochs, min_lr, max_lr, iterations) in enumerate(params):\n",
    "    acc = np.load(f\"tr{filenameSuffix}_acc{i}.npy\")\n",
    "    loss = np.load(f\"tr{filenameSuffix}_loss{i}.npy\")\n",
    "    valacc = np.load(f\"tr{filenameSuffix}_valacc{i}.npy\")\n",
    "    \n",
    "    #x1, x2 = [np.linspace(min_lr, max_lr, num) for num in [len(accuracy), len(loss)]]\n",
    "    x = range(len(valacc))\n",
    "    plt.plot(x, valacc)\n",
    "    save_file = path+f\"plot{filenameSuffix}_valacc_{batch_size}.png\"\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    print(loss[-1], acc[-1], valacc[-1])\n",
    "    print(np.min(loss), np.max(acc), np.max(valacc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
