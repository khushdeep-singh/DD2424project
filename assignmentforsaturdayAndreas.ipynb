{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import resnet as rnet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f\"using device {device}\")\n",
    "\n",
    "path = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateFunc(model, val_loader, batches):\n",
    "    valacc = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i, (images, targets) in enumerate(val_loader):\n",
    "        if i >= batches:\n",
    "            break\n",
    "        if cuda_available: \n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        t = time.time()\n",
    "        prediction = model.forward(images)\n",
    "\n",
    "        valacc = valacc + [get_xent_acc(prediction, targets)]\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    return valacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneh(labels):\n",
    "    oneh_labels = np.zeros([labels.shape[0], 10])\n",
    "    indexes = np.array([np.arange(0,labels.shape[0]), labels.numpy()])\n",
    "    oneh_labels[tuple(indexes)] = 1.0\n",
    "    return torch.tensor(oneh_labels).long()\n",
    "def get_xent_acc(prediction, labels):\n",
    "    prediction = prediction.cpu().data.numpy()\n",
    "    labels = labels.cpu().data.numpy()\n",
    "    predicted_labels = np.argmax(prediction,1)\n",
    "    return sum((predicted_labels - labels) == 0)/predicted_labels.shape[0]\n",
    "def xent_softmax(prediction):\n",
    "    pred = np.exp(prediction.cpu().data.numpy())\n",
    "    divide = np.repeat(pred.sum(1).reshape(pred.shape[0],1), pred.shape[1],1)\n",
    "    pred = np.divide(pred,divide)\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainFunc(model, lossfn, optimizer, data_loader, val_loader, n_epochs=1, validation_interval=10):\n",
    "    start    = time.time()\n",
    "    accuracy = [] \n",
    "    loss     = []\n",
    "    valacc   = []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    print(\"starting training\")\n",
    "    \n",
    "    updateStep = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        data_iterator = iter(data_loader)\n",
    "        for i, (images, labels) in enumerate(data_iterator):\n",
    "            t = time.time()\n",
    "\n",
    "            f\"\"\"if we use GPU, input- and target-tensors must be loaded on GPU as well.\"\"\"\n",
    "            if cuda_available: \n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            prediction = model.forward(images)\n",
    "            output     = lossfn(prediction, labels)\n",
    "\n",
    "            accuracy = accuracy + [get_xent_acc(prediction, labels)]\n",
    "            loss     = loss + [output]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output.backward() # calculates gradients \n",
    "            optimizer.step()  # updates weights\n",
    "\n",
    "            if validation_interval > 0 and updateStep % validation_interval == 0:\n",
    "                valacc = valacc + validateFunc(model, val_loader, 1)\n",
    "            updateStep += 1\n",
    "\n",
    "        print(f\"\"\"time passed after training {epoch} epochs is {time.time()-start} seconds\"\"\")\n",
    "    return (accuracy, loss, valacc)\n",
    "\n",
    "def cuda(thing):\n",
    "    if cuda_available:\n",
    "        return thing.cuda()\n",
    "    return thing\n",
    "\n",
    "def range_test(net,opt,dataloader,lossfn,min_lr,max_lr,iterations,batchsize):\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(opt, min_lr, max_lr, \n",
    "                                                  step_size_up=iterations, step_size_down=0, \n",
    "                                                  base_momentum=0,\n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "    start    = time.time()\n",
    "    time_int = 100\n",
    "    \n",
    "    accuracy  = []\n",
    "    loss      = []\n",
    "    interval  = 5\n",
    "    i         = 0\n",
    "    while i < iterations:\n",
    "        datait = iter(dataloader)\n",
    "        for n, (images, labels) in enumerate(datait):\n",
    "            images, labels = cuda(images), cuda(labels)\n",
    "            prediction = net.forward(images)\n",
    "            output     = lossfn(prediction, labels)\n",
    "            # Use accuracy on training-set\n",
    "            if i % interval == 0:\n",
    "                accuracy   = accuracy + [get_xent_acc(prediction, labels)]\n",
    "                loss       = loss + [output]\n",
    "            opt.zero_grad()   # clear gradients from previous time-step \n",
    "            output.backward() # calculates gradients \n",
    "            opt.step()        # updates weights\n",
    "            scheduler.step()  # change learning-rate in range_optimizer\n",
    "            if i % time_int == 0:\n",
    "                print(f\"time after {i} iterations: {time.time() - start} seconds\")\n",
    "                \n",
    "            i += 1\n",
    "            if i >= iterations:\n",
    "                break\n",
    "                \n",
    "    print(f\"time after {i} iterations: {time.time() - start} seconds\")\n",
    "            \n",
    "    f\"\"\"make and save plot of accuracy\"\"\"\n",
    "    x1, x2 = [np.linspace(min_lr, max_lr, num) for num in [len(accuracy), len(loss)]]\n",
    "    plt.plot(x1, np.array(accuracy))\n",
    "    momentum = opt.param_groups[-1]['momentum']\n",
    "    weightdecay = opt.param_groups[-1]['weight_decay']\n",
    "    save_file = path+f\"/rangetest/acc_bs{batchsize}_minlr{min_lr}_maxlr{max_lr}_iterations{iterations}_momentum{momentum}_weightdecy{weightdecay}.png\"\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create loss function \n",
    "#### https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_xent = nn.CrossEntropyLoss()\n",
    "loss_mse  = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play with forward and backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNet(batch_size, min_lr=None, max_lr=None, iterations=None):\n",
    "    # Configure\n",
    "    resnet = rnet.resnet56()\n",
    "    optimizer = optim.SGD(resnet.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0.95,\n",
    "                          weight_decay=1e-4)\n",
    "    rt_optimizer = optim.SGD(resnet.parameters(),\n",
    "                          lr=0.1,\n",
    "                          momentum=0,\n",
    "                          weight_decay=0)\n",
    "    \n",
    "    scheduler = None\n",
    "    if min_lr != None and max_lr != None:\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, min_lr, max_lr, \n",
    "                                                  step_size_up=iterations, step_size_down=iterations, \n",
    "                                                  base_momentum=0.95,\n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(path, train=True, transform=transforms.Compose([\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                #transforms.RandomCrop(32, 4),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]), download=True),\n",
    "            batch_size=batch_size, shuffle=True,\n",
    "            num_workers=0, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(path, train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=True)\n",
    "    \n",
    "    cuda(resnet)\n",
    "    \n",
    "    return (resnet, optimizer, rt_optimizer, scheduler, data_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "LambdaLayer\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "LambdaLayer\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "Sequential\n",
      "BasicBlock\n",
      "Sequential\n",
      "Linear\n",
      "ResNet\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "time after 0 iterations: 0.14654755592346191 seconds\n",
      "time after 100 iterations: 20.141679763793945 seconds\n",
      "time after 200 iterations: 40.01632285118103 seconds\n",
      "time after 300 iterations: 59.908048152923584 seconds\n",
      "time after 400 iterations: 79.67066383361816 seconds\n",
      "time after 500 iterations: 99.54656910896301 seconds\n",
      "time after 600 iterations: 119.44300031661987 seconds\n",
      "time after 700 iterations: 139.37124228477478 seconds\n",
      "time after 800 iterations: 159.2528736591339 seconds\n",
      "time after 900 iterations: 179.14980578422546 seconds\n",
      "time after 1000 iterations: 199.00088834762573 seconds\n",
      "time after 1100 iterations: 218.86657071113586 seconds\n",
      "time after 1200 iterations: 238.7532868385315 seconds\n",
      "time after 1300 iterations: 258.6556193828583 seconds\n",
      "time after 1400 iterations: 278.6520199775696 seconds\n",
      "time after 1500 iterations: 298.55948519706726 seconds\n",
      "time after 1600 iterations: 318.4445209503174 seconds\n",
      "time after 1700 iterations: 338.3434498310089 seconds\n",
      "time after 1800 iterations: 358.21958327293396 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a9bc71e310b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrt_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrt_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_xent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m<<\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"rt_acc{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"rt_loss{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0e9b2982bff0>\u001b[0m in \u001b[0;36mrange_test\u001b[0;34m(net, opt, dataloader, lossfn, min_lr, max_lr, iterations, batchsize)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdatait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0moutput\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0e9b2982bff0>\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = [(1024, 116, 0.1, 1, 49*116),\n",
    "         (512, 95, 0.08, 0.8, 98*95),\n",
    "         (256, 70, 0.06, 0.6, 196*70),\n",
    "         (128, 48, 0.04, 0.4, 391*48)]\n",
    "params.reverse()\n",
    "\n",
    "for i, (batch_size, epochs, min_lr, max_lr, iterations) in enumerate(params):\n",
    "    (model, optimizer, rt_optimizer, scheduler, data_loader, val_loader) = getNet(batch_size, min_lr, max_lr, iterations/2)\n",
    "    (acc, loss) = range_test(model, rt_optimizer, data_loader, loss_xent, 0, 1, 10000/(1<<i), batch_size)\n",
    "    np.save(f\"rt_acc{i}\", acc)\n",
    "    np.save(f\"rt_loss{i}\", loss)\n",
    "    torch.save(model.state_dict(), f\"rt_model{i}\")\n",
    "    \n",
    "\n",
    "for i, (batch_size, epochs, min_lr, max_lr, iterations) in enumerate(params):\n",
    "    (model, optimizer, rt_optimizer, scheduler, data_loader, val_loader) = getNet(batch_size, min_lr, max_lr, iterations/2)\n",
    "    (acc, loss, valacc) = trainFunc(model, nn.CrossEntropyLoss(), optimizer, data_loader, val_loader, epochs*0+1, validation_interval=50)\n",
    "    np.save(f\"tr_acc{i}\", acc)\n",
    "    np.save(f\"tr_loss{i}\", loss)\n",
    "    np.save(f\"tr_valacc{i}\", valacc)\n",
    "    torch.save(model.state_dict(), f\"tr_model{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "time passed after training 0 epochs is 72.99567341804504 seconds\n",
      "time passed after training 1 epochs is 145.88864588737488 seconds\n",
      "time passed after training 2 epochs is 218.73821830749512 seconds\n",
      "time passed after training 3 epochs is 291.6378061771393 seconds\n",
      "time passed after training 4 epochs is 364.54217982292175 seconds\n",
      "time passed after training 5 epochs is 437.41723442077637 seconds\n",
      "time passed after training 6 epochs is 510.2117099761963 seconds\n",
      "time passed after training 7 epochs is 583.07528424263 seconds\n",
      "time passed after training 8 epochs is 655.9146082401276 seconds\n",
      "time passed after training 9 epochs is 728.7469797134399 seconds\n",
      "time passed after training 10 epochs is 801.4734983444214 seconds\n",
      "time passed after training 11 epochs is 874.3388056755066 seconds\n",
      "time passed after training 12 epochs is 947.174468755722 seconds\n",
      "time passed after training 13 epochs is 1019.9657804965973 seconds\n",
      "time passed after training 14 epochs is 1092.7547574043274 seconds\n",
      "time passed after training 15 epochs is 1165.5081338882446 seconds\n",
      "time passed after training 16 epochs is 1238.3246405124664 seconds\n",
      "time passed after training 17 epochs is 1311.1405696868896 seconds\n",
      "time passed after training 18 epochs is 1383.9726305007935 seconds\n",
      "time passed after training 19 epochs is 1456.7655229568481 seconds\n",
      "time passed after training 20 epochs is 1529.572581768036 seconds\n",
      "time passed after training 21 epochs is 1602.4492990970612 seconds\n",
      "time passed after training 22 epochs is 1675.2258639335632 seconds\n",
      "time passed after training 23 epochs is 1748.0430526733398 seconds\n",
      "time passed after training 24 epochs is 1820.862915277481 seconds\n",
      "time passed after training 25 epochs is 1893.7325892448425 seconds\n",
      "time passed after training 26 epochs is 1966.6239721775055 seconds\n",
      "time passed after training 27 epochs is 2039.399787902832 seconds\n",
      "time passed after training 28 epochs is 2112.2668886184692 seconds\n",
      "time passed after training 29 epochs is 2185.1777415275574 seconds\n",
      "time passed after training 30 epochs is 2258.042624473572 seconds\n",
      "time passed after training 31 epochs is 2330.857275724411 seconds\n",
      "time passed after training 32 epochs is 2403.6790084838867 seconds\n",
      "time passed after training 33 epochs is 2476.5849299430847 seconds\n",
      "time passed after training 34 epochs is 2549.509553670883 seconds\n",
      "time passed after training 35 epochs is 2622.3391194343567 seconds\n",
      "time passed after training 36 epochs is 2695.1489577293396 seconds\n",
      "time passed after training 37 epochs is 2767.9908747673035 seconds\n",
      "time passed after training 38 epochs is 2840.8699469566345 seconds\n",
      "time passed after training 39 epochs is 2913.722289800644 seconds\n"
     ]
    }
   ],
   "source": [
    "(accuracy, loss, validationacc) = trainFunc(resnet, nn.CrossEntropyLoss(), optimizer, n_epochs=40, validation_interval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.append((accuracy, loss, validationacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e2248ee10>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,len(accuracy))\n",
    "plt.plot(x,np.array(accuracy),np.array(loss))\n",
    "x = np.arange(0,len(validationacc))\n",
    "plt.plot(x, np.array(validationacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0831\n",
      "acc 0.8143727\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "valacc = validateFunc(resnet, 100)\n",
    "print(f\"{time.time()-t:2.4f}\\nacc {np.mean(valacc):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0bc8adb8d25b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "if cuda_available:\n",
    "    images = images.cpu()\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet161()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
