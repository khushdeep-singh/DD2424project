{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ola/Documents/DD2424project\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)\n",
    "mdl_savefile = path+\"/models/resnet56_cumultrain_parameters.pickle\"\n",
    "mdl_loadfile = mdl_savefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-56 https://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal(m.weight)\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Olas Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model(model):\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "def make_oneh(labels):\n",
    "    oneh_labels = np.zeros([labels.shape[0], 10])\n",
    "    indexes = np.array([np.arange(0,labels.shape[0]), labels.numpy()])\n",
    "    oneh_labels[tuple(indexes)] = 1.0\n",
    "    return torch.tensor(oneh_labels).long()\n",
    "def get_xent_acc(prediction, labels):\n",
    "    predicted_labels = np.argmax(prediction.cpu().data.numpy(),1)\n",
    "    (predicted_labels - labels.cpu().data.numpy())\n",
    "    return sum((predicted_labels - labels.cpu().data.numpy()) == 0)/predicted_labels.shape[0]\n",
    "def xent_softmax(prediction):\n",
    "    pred = np.exp(prediction.cpu().data.numpy())\n",
    "    divide = np.repeat(pred.sum(1).reshape(pred.shape[0],1), pred.shape[1],1)\n",
    "    pred = np.divide(pred,divide)\n",
    "    return pred \n",
    "def get_valacc(valacc, valloss):\n",
    "    with torch.no_grad():\n",
    "        f\"\"\"certain layers have different properties during evaluation e.g dropout. \n",
    "            therefor we use resnet.eval()\"\"\"\n",
    "        resnet.eval()      \n",
    "        for i, (valimgs, vallabels) in enumerate(valid_data_loader):\n",
    "            if cuda_available: \n",
    "                valimgs   = valimgs.cuda()\n",
    "                vallabels = vallabels.cuda()\n",
    "            valprediction = resnet.forward(valimgs)    \n",
    "            valloss = valloss + [loss_xent(valprediction, vallabels)]\n",
    "            valacc = valacc + [get_xent_acc(valprediction, vallabels)]\n",
    "            break\n",
    "        f\"\"\"reset resnet for training with resnet.train()\"\"\"\n",
    "        resnet.train()\n",
    "    return valacc, valloss\n",
    "def compare_parameters(net1, net2):\n",
    "    f\"\"\"compare parameters of two models with the same architecture\"\"\" \n",
    "    net1_param, net2_param, diff = [], [], 0\n",
    "    for param_tensor in net1.state_dict():\n",
    "        net1_param = net1_param + [net1.state_dict()[param_tensor]]\n",
    "        net2_param = net2_param + [net2.state_dict()[param_tensor]]\n",
    "    for i in range(len(net1_param)):\n",
    "        diff = diff + np.sum(net1_param[i].cpu().numpy() - net2_param[i].cpu().numpy())\n",
    "    print(f\"\"\"difference in weights and biases is: {diff} between network1 and network2\"\"\")\n",
    "def load_cifar10(batchsize):\n",
    "    torchvision.datasets.CIFAR10(path,download=True)\n",
    "    f\"\"\"adding transform ToTensor(); transforms PIL-images to tensor-format used by PyTorch\"\"\" \n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "    cifar10_train = torchvision.datasets.CIFAR10(path, train=True, transform=transform)\n",
    "    cifar10_valid = torchvision.datasets.CIFAR10(path, train=False,transform=transform)\n",
    "    dataloader_tr = torch.utils.data.DataLoader(cifar10_train,\n",
    "                                              batch_size=batchsize,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              pin_memory=True)\n",
    "    dataloader_vl = torch.utils.data.DataLoader(cifar10_valid,\n",
    "                                              batch_size=batchsize,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              pin_memory=True)\n",
    "    return dataloader_tr, dataloader_vl\n",
    "def range_test(net,opt,dataloader,lossfn,max_lr,min_lr,iterations,batchsize):\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(opt, min_lr, max_lr, \n",
    "                                                  step_size_up=iterations, step_size_down=0, \n",
    "                                                  mode='triangular', cycle_momentum=False)\n",
    "    start    = time.time()\n",
    "    time_int = 100\n",
    "    \n",
    "    accuracy  = []\n",
    "    loss      = []\n",
    "    datait    = iter(dataloader)\n",
    "    n_batches = len(datait)\n",
    "    interval  = 5\n",
    "    batch     = 0\n",
    "    for i in range(1,iterations):\n",
    "        batch += 1\n",
    "        if batch >= n_batches:\n",
    "            datait = iter(dataloader)\n",
    "            batch = 0 \n",
    "        images, labels = datait.next() \n",
    "        if cuda_available:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        prediction = net.forward(images)\n",
    "        output     = lossfn(prediction, labels)\n",
    "        f\"\"\"Use accuracy on training-set\"\"\"\n",
    "        if i % interval == 0:\n",
    "            accuracy   = accuracy + [get_xent_acc(prediction, labels)]\n",
    "            loss       = loss + [output]\n",
    "        opt.zero_grad()   # clear gradients from previous time-step \n",
    "        output.backward() # calculates gradients \n",
    "        opt.step()        # updates weights\n",
    "        scheduler.step()  # change learning-rate in range_optimizer\n",
    "        if i % time_int == 0:\n",
    "            print(f\"\"\"time after {i} iterations: {time.time() - start} seconds\"\"\")\n",
    "            \n",
    "    f\"\"\"make and save plot of accuracy\"\"\"\n",
    "    x1, x2 = [np.linspace(min_lr, max_lr, num) for num in [len(accuracy), len(loss)]]\n",
    "    plt.plot(x1, np.array(accuracy))\n",
    "    save_file = path+f\"\"\"/rangetest/acc_bs{batchsize}_minlr{min_lr}_maxlr{max_lr}_iterations{iterations}_momentum{opt.param_groups[-1]['momentum']}_weightdecy{opt.param_groups[-1]['weight_decay']}.png\"\"\"\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning-rate range-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "network = ResNet(BasicBlock,[9,9,9])\n",
    "if cuda_available: network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "time after 100 iterations: 5.185002088546753 seconds\n",
      "time after 200 iterations: 9.91891360282898 seconds\n",
      "time after 300 iterations: 14.668192625045776 seconds\n",
      "time after 400 iterations: 19.474366664886475 seconds\n",
      "time after 500 iterations: 24.26847243309021 seconds\n",
      "time after 600 iterations: 29.057965993881226 seconds\n",
      "time after 700 iterations: 33.846057415008545 seconds\n",
      "time after 800 iterations: 38.63677930831909 seconds\n",
      "time after 900 iterations: 43.41744637489319 seconds\n",
      "time after 1000 iterations: 48.193164587020874 seconds\n",
      "time after 1100 iterations: 52.97568464279175 seconds\n",
      "time after 1200 iterations: 57.77593660354614 seconds\n",
      "time after 1300 iterations: 62.55843138694763 seconds\n",
      "time after 1400 iterations: 67.34149861335754 seconds\n",
      "time after 1500 iterations: 72.1842794418335 seconds\n",
      "time after 1600 iterations: 76.94144749641418 seconds\n",
      "time after 1700 iterations: 81.68990874290466 seconds\n",
      "time after 1800 iterations: 86.42535448074341 seconds\n",
      "time after 1900 iterations: 91.16648387908936 seconds\n",
      "time after 2000 iterations: 95.90310835838318 seconds\n",
      "time after 2100 iterations: 100.64876294136047 seconds\n",
      "time after 2200 iterations: 105.39040780067444 seconds\n",
      "time after 2300 iterations: 110.13356304168701 seconds\n",
      "time after 2400 iterations: 114.87480306625366 seconds\n",
      "time after 2500 iterations: 119.85244679450989 seconds\n",
      "time after 2600 iterations: 124.65376830101013 seconds\n",
      "time after 2700 iterations: 129.49202704429626 seconds\n",
      "time after 2800 iterations: 134.32819199562073 seconds\n",
      "time after 2900 iterations: 139.21803212165833 seconds\n",
      "time after 3000 iterations: 144.06377005577087 seconds\n",
      "time after 3100 iterations: 148.92832851409912 seconds\n",
      "time after 3200 iterations: 153.7754921913147 seconds\n",
      "time after 3300 iterations: 158.60477757453918 seconds\n",
      "time after 3400 iterations: 163.33472657203674 seconds\n",
      "time after 3500 iterations: 168.06984996795654 seconds\n",
      "time after 3600 iterations: 172.80370593070984 seconds\n",
      "time after 3700 iterations: 177.61016011238098 seconds\n",
      "time after 3800 iterations: 182.34723734855652 seconds\n",
      "time after 3900 iterations: 187.07589197158813 seconds\n"
     ]
    }
   ],
   "source": [
    "max_lr = 1e1\n",
    "min_lr = 1e-6\n",
    "iterations = 4000\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(network.parameters(), lr=min_lr, \n",
    "                      momentum=0.95, weight_decay=1e-6)\n",
    "for batchsize in [128]:\n",
    "    dataloader_tr, dataloader_vl = load_cifar10(batchsize)\n",
    "    accuracy, loss = range_test(network,optimizer,dataloader_tr,lossfn,max_lr,min_lr,iterations,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = [np.linspace(1e-10, 1e-4, num) for num in [len(accuracy), len(loss)]]\n",
    "plt.plot(x1, np.array(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "dataloader_tr, dataloader_vl = load_cifar10(batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "f\"\"\"To get ResNet56 use ResNet(BasicBlock,[9,9,9])\"\"\" \n",
    "resnet56 = ResNet(BasicBlock,[9,9,9])\n",
    "if cuda_available: resnet56.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss-function    https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_xent = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize-function https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(resnet56.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# play with forward and backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start    = time.time()\n",
    "f\"\"\"load previous model\"\"\"\n",
    "# if os.path.isfile(load_filename):\n",
    "#     resnet.load_state_dict(torch.load(load_filename))\n",
    "n_epoch  = 1\n",
    "validation_interval = 10\n",
    "\n",
    "trainacc  = [] \n",
    "valacc    = [] \n",
    "trainloss = []\n",
    "valloss   = [] \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_iterator = iter(train_data_loader)\n",
    "    for i in range(len(train_iterator)):\n",
    "        images, labels = train_iterator.next()\n",
    "        \n",
    "        f\"\"\"if we use GPU, input- and target-tensors must be loaded on GPU as well.\"\"\"\n",
    "        if cuda_available: images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "        prediction = resnet.forward(images)\n",
    "        output     = loss_xent(prediction, labels)\n",
    "        \n",
    "        trainacc = trainacc + [get_xent_acc(prediction, labels)]\n",
    "        trainloss = trainloss + [output]\n",
    "        \n",
    "        f\"\"\"using zero_grad() seems to be necessary. step() does not clear the gradients\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        output.backward() # calculates gradients \n",
    "        optimizer.step()  # updates weights\n",
    "        \n",
    "        if i % validation_interval == 0:\n",
    "            valacc, valloss = get_valacc(valacc, valloss)\n",
    "            \n",
    "    print(f\"\"\"time passed after training {epoch+1} epochs is {time.time()-start} seconds\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = [np.linspace(0, len(trainacc), num) for num in [len(trainloss), len(trainacc), len(valacc)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x1,np.array(trainloss))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x2,np.array(trainacc))\n",
    "plt.plot(x3,np.array(valacc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load Model\n",
    "### https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "f\"\"\"save\"\"\"\n",
    "torch.save(resnet.state_dict(), save_filename)\n",
    "f\"\"\"load\"\"\"\n",
    "resnet2 = ResNet(BasicBlock,[9,9,9])\n",
    "resnet2.load_state_dict(torch.load(load_filename))\n",
    "compare_parameters(resnet,resnet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet161()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
