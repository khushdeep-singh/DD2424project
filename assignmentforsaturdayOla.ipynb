{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/DD2424project\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)\n",
    "save_filename = path+\"/models/resnet56_cumultrain_parameters.pickle\"\n",
    "load_filename = save_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model(model):\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "def make_oneh(labels):\n",
    "    oneh_labels = np.zeros([labels.shape[0], 10])\n",
    "    indexes = np.array([np.arange(0,labels.shape[0]), labels.numpy()])\n",
    "    oneh_labels[tuple(indexes)] = 1.0\n",
    "    return torch.tensor(oneh_labels).long()\n",
    "def get_xent_acc(prediction, labels):\n",
    "    predicted_labels = np.argmax(prediction.cpu().data.numpy(),1)\n",
    "    (predicted_labels - labels.cpu().data.numpy())\n",
    "    return sum((predicted_labels - labels.cpu().data.numpy()) == 0)/predicted_labels.shape[0]\n",
    "def xent_softmax(prediction):\n",
    "    pred = np.exp(prediction.cpu().data.numpy())\n",
    "    divide = np.repeat(pred.sum(1).reshape(pred.shape[0],1), pred.shape[1],1)\n",
    "    pred = np.divide(pred,divide)\n",
    "    return pred \n",
    "def get_valacc(valacc, valloss):\n",
    "    with torch.no_grad():\n",
    "        f\"\"\"certain layers have different properties during evaluation e.g dropout. \n",
    "            therefor we use resnet.eval()\"\"\"\n",
    "        resnet.eval()      \n",
    "        for i, (valimgs, vallabels) in enumerate(valid_data_loader):\n",
    "            if cuda_available: \n",
    "                valimgs   = valimgs.cuda()\n",
    "                vallabels = vallabels.cuda()\n",
    "            valprediction = resnet.forward(valimgs)    \n",
    "            valloss = valloss + [loss_xent(valprediction, vallabels)]\n",
    "            valacc = valacc + [get_xent_acc(valprediction, vallabels)]\n",
    "            break\n",
    "        f\"\"\"reset resnet for training with resnet.train()\"\"\"\n",
    "        resnet.train()\n",
    "    return valacc, valloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Split: train\n",
       "    Root Location: /home/r2/Documents/DD2424project\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.datasets.CIFAR10(path,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"\"\"adding transform ToTensor(); transforms PIL-images to tensor-format used by PyTorch\"\"\" \n",
    "batch_size = 64\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "cifar10_train = torchvision.datasets.CIFAR10(path, train=True, transform=transform)\n",
    "cifar10_valid = torchvision.datasets.CIFAR10(path, train=False,transform=transform)\n",
    "train_data_loader = torch.utils.data.DataLoader(cifar10_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0,\n",
    "                                          pin_memory=True)\n",
    "valid_data_loader = torch.utils.data.DataLoader(cifar10_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0,\n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-56\n",
    "#### https://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "f\"\"\"To get ResNet56 use ResNet(BasicBlock,[9,9,9])\"\"\" \n",
    "resnet = ResNet(BasicBlock,[9,9,9])\n",
    "if cuda_available: \n",
    "    resnet.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create loss function \n",
    "#### https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_xent = nn.CrossEntropyLoss()\n",
    "loss_mse  = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add pytorch-optimizer to use custom update-rules\n",
    "### https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclical learner schedule built into pytorch: \n",
    "#### torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(resnet.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play with forward and backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time passed after training 1 epochs is 30.157015800476074 seconds\n"
     ]
    }
   ],
   "source": [
    "start    = time.time()\n",
    "f\"\"\"load previous model\"\"\"\n",
    "# if os.path.isfile(load_filename):\n",
    "#     resnet.load_state_dict(torch.load(load_filename))\n",
    "n_epoch  = 1\n",
    "validation_interval = 10\n",
    "\n",
    "trainacc  = [] \n",
    "valacc    = [] \n",
    "trainloss = []\n",
    "valloss   = [] \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_iterator = iter(train_data_loader)\n",
    "    for i in range(len(train_iterator)):\n",
    "        images, labels = train_iterator.next()\n",
    "        \n",
    "        f\"\"\"if we use GPU, input- and target-tensors must be loaded on GPU as well.\"\"\"\n",
    "        if cuda_available: \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        prediction = resnet.forward(images)\n",
    "        output     = loss_xent(prediction, labels)\n",
    "        \n",
    "        trainacc = trainacc + [get_xent_acc(prediction, labels)]\n",
    "        trainloss = trainloss + [output]\n",
    "        \n",
    "        f\"\"\"using zero_grad() seems to be necessary. step() does not clear the gradients\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        output.backward() # calculates gradients \n",
    "        optimizer.step()  # updates weights\n",
    "        \n",
    "        if i % validation_interval == 0:\n",
    "            valacc, valloss = get_valacc(valacc, valloss)\n",
    "            \n",
    "    print(f\"\"\"time passed after training {epoch+1} epochs is {time.time()-start} seconds\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = [np.linspace(0, len(trainacc), num) for num in [len(loss), len(trainacc), len(valacc)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x1,np.array(loss))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x2,np.array(trainacc))\n",
    "plt.plot(x3,np.array(valacc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load Model\n",
    "### https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "f\"\"\"save\"\"\"\n",
    "torch.save(resnet.state_dict(), save_filename)\n",
    "f\"\"\"load\"\"\"\n",
    "resnet2 = ResNet(BasicBlock,[9,9,9])\n",
    "resnet2.load_state_dict(torch.load(load_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"\"\"compare saved and loaded models parameters\"\"\" \n",
    "net1_param, net2_param, diff = [], [], 0\n",
    "for param_tensor in resnet.state_dict():\n",
    "    net1_param = net1_param + [resnet.state_dict()[param_tensor]]\n",
    "    net2_param = net2_param + [resnet2.state_dict()[param_tensor]]\n",
    "for i in range(len(net1_param)):\n",
    "    diff = diff + np.sum(net1_param[i].cpu().numpy() - net2_param[i].cpu().numpy())\n",
    "print(f\"\"\"difference in weights and biases is: {diff} between the saved and the loaded network\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet161()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
